{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx8mgISVCl1MBCm3gTKTa4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshhan619/HandsOnEgoVLP/blob/main/egovqa_handsonvlm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmXoTCQMyjG8",
        "outputId": "5bc40c18-d7cb-4971-ad5e-c39b7932d752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded file to EgoVLPv2.pth\n"
          ]
        }
      ],
      "source": [
        "# Download the pretrained EgoVLPv2 checkpoint\n",
        "\n",
        "import requests\n",
        "\n",
        "def download_file(url, filename):\n",
        "  \"\"\"Downloads a file from a URL to a local file.\"\"\"\n",
        "  response = requests.get(url, stream=True)\n",
        "  with open(filename, 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "      f.write(chunk)\n",
        "\n",
        "url = \"https://www.cis.jhu.edu/~shraman/EgoVLPv2/ckpts/Pre-trained/EgoVLPv2.pth\"\n",
        "filename = \"EgoVLPv2.pth\"\n",
        "\n",
        "download_file(url, filename)\n",
        "print(f\"Downloaded file to {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Load the EgoVLPv2 model on https://github.com/facebookresearch/EgoVLPv2\n",
        "\n",
        "import torch\n",
        "from models.EgoVLPv2 import EgoVLPv2\n",
        "\n",
        "# Load the pretrained EgoVLPv2 checkpoint\n",
        "checkpoint_path = \"EgoVLPv2.pth\"  # Path to the downloaded checkpoint\n",
        "model = EgoVLPv2.from_pretrained(checkpoint_path)\n",
        "model.eval()\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have preprocessed video and text inputs\n",
        "# video_input = ...\n",
        "# text_input = ...\n",
        "# with torch.no_grad():\n",
        "#   outputs = model(video_input, text_input)\n",
        "#   ...\n"
      ],
      "metadata": {
        "id": "FoujM-spAZ0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Assuming you have the model architecture defined\n",
        "checkpoint = torch.load(\"EgoVLPv2.pth\", map_location=torch.device('cpu'))  # Load the checkpoint\n",
        "\n",
        "# Load the state dict into your model\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# You can also load the optimizer state if needed:\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# Optionally, load the epoch or other information:\n",
        "# epoch = checkpoint['epoch']\n",
        "\n",
        "print(\"Checkpoint loaded successfully.\")\n"
      ],
      "metadata": {
        "id": "tAOnDR6I_-Pe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}